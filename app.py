import streamlit as st
import os
import subprocess
import tempfile
import numpy as np
from pydub import AudioSegment
from pydub.utils import mediainfo
import noisereduce as nr
from scipy.io import wavfile
import matplotlib.pyplot as plt

# è¨­å®šé é¢é…ç½®
st.set_page_config(page_title="éŸ³è¨Šé™å™ªèˆ‡å¢å¼·å·¥å…·", page_icon="ğŸµ", layout="centered")


def extract_audio_from_video(video_path, output_audio_path):
    """
    ä½¿ç”¨ FFmpeg å¾å½±ç‰‡ä¸­åˆ†é›¢éŸ³è»Œ (æ•´åˆä½¿ç”¨è€…åŸæœ¬çš„é‚è¼¯)
    """
    command = [
        "ffmpeg",
        "-i", video_path,
        "-vn",
        "-acodec", "pcm_s16le",  # è½‰ç‚º wav æ ¼å¼ä»¥ä¾¿å¾ŒçºŒè™•ç†
        "-ar", "44100",  # è¨­å®šæ¡æ¨£ç‡
        "-ac", "1",  # è½‰ç‚ºå–®è²é“ (é™å™ªæ•ˆæœé€šå¸¸è¼ƒå¥½)
        "-y",  # è¦†è“‹å·²å­˜åœ¨æ–‡ä»¶
        output_audio_path
    ]
    try:
        subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        return True
    except subprocess.CalledProcessError as e:
        st.error(f"FFmpeg éŒ¯èª¤: {e}")
        return False

def enhance_audio(input_path, output_path):
    """
    é‡å°äººè²å„ªåŒ–ç‰ˆï¼šè®€å–éŸ³è¨Š -> å¼·åŠ›é™å™ª -> è¼¸å‡º
    """
    try:
        # 1. ä½¿ç”¨ Pydub è®€å–éŸ³è¨Š
        sound = AudioSegment.from_file(input_path)

        # è½‰æ›ç‚º numpy array ä»¥ä¾¿é€²è¡Œæ•¸å­¸é‹ç®—
        samples = np.array(sound.get_array_of_samples())

        # æ­£è¦åŒ–æ•¸æ“šåˆ° -1.0 åˆ° 1.0 ä¹‹é–“ (noisereduce éœ€è¦ float32)
        if sound.sample_width == 2:
            data = samples.astype(np.float32) / 32768.0
        elif sound.sample_width == 4:
            data = samples.astype(np.float32) / 2147483648.0
        else:
            data = samples.astype(np.float32)

        # 2. æ‡‰ç”¨é™å™ªç®—æ³• (é‡å°äººè²å„ªåŒ–åƒæ•¸)
        # stationary=False: å•Ÿç”¨éç©©æ…‹é™å™ªï¼Œé€™å°æœ‰èƒŒæ™¯èªªè©±è²çš„å½±ç‰‡æ›´æœ‰æ•ˆï¼Œä½†è™•ç†æ™‚é–“æœƒè®Šé•·
        reduced_noise_data = nr.reduce_noise(
            y=data,
            sr=sound.frame_rate,
            stationary=False,  # é—œéµä¿®æ”¹ï¼šä¸å‡è¨­å™ªéŸ³æ˜¯å›ºå®šçš„
            prop_decrease=0.9, # æ¶ˆé™¤ 90% çš„åµæ¸¬å™ªéŸ³
            n_std_thresh_stationary=1.5, # å¢åŠ åˆ¤æ–·é–¾å€¼
            time_constant_s=2.0, # å¹³æ»‘è™•ç†
        )

        # å°‡æ•¸æ“šè½‰å› int16 ä»¥ä¾¿ Pydub è®€å–
        reduced_noise_data = (reduced_noise_data * 32768.0).astype(np.int16)

        # é‡å»º AudioSegment
        cleaned_sound = AudioSegment(
            reduced_noise_data.tobytes(),
            frame_rate=sound.frame_rate,
            sample_width=2,
            channels=1
        )

        # 3. è¼¸å‡ºçµæœ (æš«æ™‚é—œé–‰ Normalize ä»¥å‡¸é¡¯é™å™ªæ•ˆæœ)
        # ç‚ºäº†æ¸¬è©¦ï¼Œæˆ‘å€‘å…ˆç›´æ¥è¼¸å‡ºè™•ç†å¾Œçš„çµæœï¼Œä¸è‡ªå‹•æ‹‰å¤§éŸ³é‡
        cleaned_sound.export(output_path, format="mp3")
        return True

    except Exception as e:
        st.error(f"è™•ç†éŸ³è¨Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return False


def plot_spectrogram(file_path, title):
    """
    ç¹ªè£½é »è­œåœ–çš„å‡½å¼
    """
    # è®€å–éŸ³è¨Š
    sound = AudioSegment.from_file(file_path)
    # è½‰æˆ numpy array
    samples = np.array(sound.get_array_of_samples())

    # è™•ç†é›™è²é“ (åªå–å·¦è²é“ç•«åœ–ï¼Œé¿å…ç¶­åº¦éŒ¯èª¤)
    if sound.channels == 2:
        samples = samples.reshape((-1, 2))[:, 0]

    # å»ºç«‹ç•«å¸ƒ
    fig, ax = plt.subplots(figsize=(10, 4))

    # ç¹ªè£½é »è­œ (NFFT=1024, noverlap=512 æ˜¯æ¨™æº–è¨­å®š)
    # cmap='inferno' æœƒè®“èƒ½é‡å¼·çš„åœ°æ–¹é¡¯ç¤ºäº®é»ƒè‰²ï¼Œå¼±çš„åœ°æ–¹é¡¯ç¤ºé»‘è‰²/ç´«è‰²ï¼Œçœ‹èµ·ä¾†å¾ˆåƒè²å­¸è»Ÿé«”
    Pxx, freqs, bins, im = ax.specgram(samples, Fs=sound.frame_rate, NFFT=1024, noverlap=512, cmap='inferno')

    ax.set_title(title)
    ax.set_ylabel('Frequency (Hz)')
    ax.set_xlabel('Time (s)')

    # å›å‚³é€™å¼µåœ–
    return fig

# --- ç¶²ç«™ä»‹é¢é‚è¼¯ ---

st.title("ğŸµ å½±ç‰‡/éŸ³è¨Š é™å™ªèˆ‡ç•«è³ªå¢å¼·å™¨")
st.markdown("ä¸Šå‚³æ‚¨çš„å½±ç‰‡æˆ–éŒ„éŸ³æª”ï¼Œæˆ‘å€‘æœƒè‡ªå‹•æå–éŸ³è¨Šä¸¦å»é™¤èƒŒæ™¯é›œéŸ³ã€‚")

# æª”æ¡ˆä¸Šå‚³å€
uploaded_file = st.file_uploader("è«‹é¸æ“‡æª”æ¡ˆ (æ”¯æ´ .mov, .mp4, .mp3, .wav)", type=["mov", "mp4", "mp3", "wav", "m4a"])

if uploaded_file is not None:
    # å»ºç«‹è‡¨æ™‚ç›®éŒ„ä¾†å­˜æ”¾æª”æ¡ˆï¼Œé¿å…è·¯å¾‘å•é¡Œ
    with tempfile.TemporaryDirectory() as temp_dir:
        input_path = os.path.join(temp_dir, uploaded_file.name)
        extracted_audio_path = os.path.join(temp_dir, "extracted_raw.wav")
        final_output_path = os.path.join(temp_dir, "cleaned_output.mp3")

        # å°‡ä¸Šå‚³çš„æª”æ¡ˆå¯«å…¥æš«å­˜å€
        with open(input_path, "wb") as f:
            f.write(uploaded_file.getbuffer())

        st.info(f"æª”æ¡ˆ `{uploaded_file.name}` ä¸Šå‚³æˆåŠŸï¼æº–å‚™è™•ç†...")

        # åˆ¤æ–·æ˜¯å¦ç‚ºå½±ç‰‡
        file_extension = os.path.splitext(input_path)[1].lower()
        is_video = file_extension in ['.mov', '.mp4', '.avi', '.mkv']

        progress_bar = st.progress(0)
        status_text = st.empty()

        # ç¬¬ä¸€æ­¥ï¼šç²å–éŸ³è¨Š
        if is_video:
            status_text.text("æ­£åœ¨å¾å½±ç‰‡ä¸­æå–éŸ³è¨Š...")
            success = extract_audio_from_video(input_path, extracted_audio_path)
            processing_source = extracted_audio_path
        else:
            status_text.text("æ­£åœ¨è®€å–éŸ³è¨Šæª”...")
            processing_source = input_path
            success = True

        progress_bar.progress(40)

        if success:
            # ç¬¬äºŒæ­¥ï¼šé™å™ªèˆ‡å¢å¼·
            status_text.text("æ­£åœ¨é€²è¡Œ AI é™å™ªè™•ç† (é€™å¯èƒ½éœ€è¦ä¸€é»æ™‚é–“ï¼Œè«‹è€å¿ƒç­‰å€™)...")
            enhancement_success = enhance_audio(processing_source, final_output_path)
            progress_bar.progress(90)

            if enhancement_success:
                progress_bar.progress(100)
                status_text.text("è™•ç†å®Œæˆï¼")
                st.success("éŸ³è¨Šå„ªåŒ–æˆåŠŸï¼")

                # é¡¯ç¤ºçµæœå°æ¯”
                col1, col2 = st.columns(2)

                with col1:
                    st.markdown("### ğŸ§ è™•ç†å‰ (åŸå§‹)")

                    # 1. æ’­æ”¾åŸå§‹æª”
                    if is_video:
                        with open(input_path, "rb") as f:
                            video_bytes = f.read()
                        st.video(video_bytes)
                    else:
                        with open(input_path, "rb") as f:
                            audio_bytes = f.read()
                        st.audio(audio_bytes)

                    # 2. é¡¯ç¤ºåŸå§‹é »è­œ (æ–°å¢çš„éƒ¨åˆ†)                     st.markdown("**åŸå§‹é »è­œåœ– (Spectrogram):**")
                    with st.spinner("æ­£åœ¨ç”ŸæˆåŸå§‹é »è­œ..."):
                        fig_original = plot_spectrogram(processing_source, "Original Audio Spectrogram")
                        st.pyplot(fig_original)
                        plt.close(fig_original)  # é‡‹æ”¾è¨˜æ†¶é«”

                with col2:
                    st.markdown("### ğŸ¹ è™•ç†å¾Œ (é™å™ª)")

                    # 1. æ’­æ”¾è™•ç†å¾Œçš„æª”
                    with open(final_output_path, "rb") as f:
                        processed_audio_bytes = f.read()
                    st.audio(processed_audio_bytes, format='audio/mp3')

                    # 2. é¡¯ç¤ºé™å™ªé »è­œ (æ–°å¢çš„éƒ¨åˆ†)
                    st.markdown("**é™å™ªå¾Œé »è­œåœ– (Spectrogram):**")
                    with st.spinner("æ­£åœ¨ç”Ÿæˆé™å™ªé »è­œ..."):
                        fig_processed = plot_spectrogram(final_output_path, "Denoised Audio Spectrogram")
                        st.pyplot(fig_processed)
                        plt.close(fig_processed)  # é‡‹æ”¾è¨˜æ†¶é«”

                    # ä¸‹è¼‰æŒ‰éˆ• (ä¿æŒåŸæœ¬çš„ä½ç½®)
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è¼‰è™•ç†å¾Œçš„ MP3",
                        data=processed_audio_bytes,
                        file_name=f"enhanced_{os.path.splitext(uploaded_file.name)[0]}.mp3",
                        mime="audio/mp3"
                    )

st.markdown("---")
st.caption("ç”± Streamlit, FFmpeg èˆ‡ Noisereduce å¼·åŠ›é©…å‹•")